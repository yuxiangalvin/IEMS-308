{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "# Import NLTK module\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('averaged_perceptron_tagger')\n",
    "# nltk.download('maxent_ne_chunker')\n",
    "# nltk.download('words')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.stem import PorterStemmer \n",
    "ps = PorterStemmer() \n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import spacy \n",
    "import en_core_web_sm\n",
    "\n",
    "import re\n",
    "import string \n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_word_list = ['%', 'percent', 'percents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_all_percent_re(article_str):\n",
    "    percent_signs = re.findall('[0-9+-.,/]+%', article_str)\n",
    "    percent_texts = re.findall('[0-9+-.,/a-zA-Z]* ?percent+[a-zA-Z]*', article_str)\n",
    "    percent_point_texts = re.findall('[0-9+-.,/a-zA-Z]*\\s?percent+[a-zA-Z]*\\s?(?:point|Point)s?', article_str)\n",
    "    of_a_percent_point_texts = re.findall('[0-9+-.,/a-zA-Z]*\\sof\\sa\\s?percent+[a-zA-Z]*\\s?(?:point|Point)s?', article_str)\n",
    "    return percent_signs + percent_texts + percent_point_texts + of_a_percent_point_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['225,23%', '20.3%', 'one%', '46.00%']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[0-9+-.,a-zA-Z]+%', '225,23% and 20.3% and one%and 46.00%%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10percent', ',0.3 percentage', '20.33 percents', 'Thirty-one percent']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[0-9+-.,a-zA-Z]*\\s?percent+[a-zA-Z]*', \n",
    "           ', 10percent and 2&,0.3 percentage and 20.33 percents hah and Thirty-one percent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10percent points', '0.3 percentage point']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[0-9+-.,a-zA-Z]*\\s?percent+[a-zA-Z]*\\s?(?:point|Point)s?', \n",
    "           ', 10percent points and 0.3 percentage point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['half of a percentage points']"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall('[0-9+-.,/a-zA-Z]*\\sof\\sa\\s?percent+[a-zA-Z]*\\s?(?:point|Point)s?', 'a half of a percentage points is hahaha a percent point')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def extract_all_percent(article_str, percent_word_list): \n",
    "#     tokens_list = word_tokenize(article_str)\n",
    "#     extracted_percent_list = []\n",
    "\n",
    "#     for i in range(len(tokens_list)):\n",
    "#         word = tokens_list[i]\n",
    "#         for percent_word in percent_word_list:\n",
    "#             if (percent_word in word) and word !='percentage':\n",
    "#                 percent_exist = False\n",
    "\n",
    "#                 candidate_seg_str = ''\n",
    "#     #             candidate_list = tokens_list[max(0,i-4) : min(len(tokens_list)-1, i+5)]\n",
    "\n",
    "#                 for j in range(max(0,i-4), min(len(tokens_list)-1, i+5)):\n",
    "#                     adjacent_word = tokens_list[j]\n",
    "#                     if (adjacent_word in percent_word_list) and (j < i):\n",
    "#                         candidate_seg_str = ''     \n",
    "#                     elif (adjacent_word in percent_word_list) and (j > i):\n",
    "#                         break\n",
    "#                     elif adjacent_word not in string.punctuation:\n",
    "#                         candidate_seg_str = candidate_seg_str + ' ' + adjacent_word\n",
    "#                     else:\n",
    "#                         candidate_seg_str = candidate_seg_str + adjacent_word\n",
    "#                 #remove the first space \n",
    "#                 candidate_seg_str = candidate_seg_str[1:]   \n",
    "#                 entities = nlp(candidate_seg_str).ents\n",
    "\n",
    "#                 for ent in entities:\n",
    "#                     if ent.label_ == 'PERCENT':\n",
    "#     #                     print(ent.text)\n",
    "#                         extracted_percent_list.append(ent.text)\n",
    "#                         percent_exist = True\n",
    "\n",
    "#                 if percent_exist == False:\n",
    "#                     cardinal_word_index_smallest = 1000\n",
    "#                     cardinal_word_index_biggest = 0\n",
    "#                     for ent in entities:\n",
    "#                         if ent.label_ == 'CARDINAL':\n",
    "#                             cardinal_word_index_smallest = min(cardinal_word_index_smallest, ent.start_char)\n",
    "#                             cardinal_word_index_biggest = max(cardinal_word_index_biggest, ent.end_char+1)\n",
    "#                             cardinal_word_index_smallest = min(cardinal_word_index_smallest, candidate_seg_str.find(percent_word))\n",
    "#                             cardinal_word_index_biggest = max(cardinal_word_index_biggest, candidate_seg_str.find(percent_word)+len(percent_word))\n",
    "\n",
    "#                             if cardinal_word_index_smallest < cardinal_word_index_biggest:\n",
    "#                                 extracted_percent_list.append(candidate_seg_str[cardinal_word_index_smallest:cardinal_word_index_biggest])\n",
    "#     #                             print('*****', candidate_seg_str[cardinal_word_index_smallest:cardinal_word_index_biggest])\n",
    "#     return extracted_percent_list\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/730\n",
      "20/730\n",
      "30/730\n",
      "40/730\n",
      "50/730\n",
      "60/730\n",
      "70/730\n",
      "80/730\n",
      "90/730\n",
      "100/730\n",
      "110/730\n",
      "120/730\n",
      "130/730\n",
      "140/730\n",
      "150/730\n",
      "160/730\n",
      "170/730\n",
      "180/730\n",
      "190/730\n",
      "200/730\n",
      "210/730\n",
      "220/730\n",
      "230/730\n",
      "240/730\n",
      "250/730\n",
      "260/730\n",
      "270/730\n",
      "280/730\n",
      "290/730\n",
      "300/730\n",
      "310/730\n",
      "320/730\n",
      "330/730\n",
      "340/730\n",
      "350/730\n",
      "360/730\n",
      "370/730\n",
      "380/730\n",
      "390/730\n",
      "400/730\n",
      "410/730\n",
      "420/730\n",
      "430/730\n",
      "440/730\n",
      "450/730\n",
      "460/730\n",
      "470/730\n",
      "480/730\n",
      "490/730\n",
      "500/730\n",
      "510/730\n",
      "520/730\n",
      "530/730\n",
      "540/730\n",
      "550/730\n",
      "560/730\n",
      "570/730\n",
      "580/730\n",
      "590/730\n",
      "600/730\n",
      "610/730\n",
      "620/730\n",
      "630/730\n",
      "640/730\n",
      "650/730\n",
      "660/730\n",
      "670/730\n",
      "680/730\n",
      "690/730\n",
      "700/730\n",
      "710/730\n",
      "720/730\n",
      "730/730\n"
     ]
    }
   ],
   "source": [
    "result_dict_re = {}\n",
    "count = 0\n",
    "directory_list = [f'./BI-articles/2013',f'./BI-articles/2014']\n",
    "for directory in directory_list:\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".txt\"):\n",
    "                    \n",
    "\n",
    "            with open(directory +'/'+ filename,'r', errors='replace') as f:\n",
    "                lines = f.readlines()\n",
    "            out = [(\" \" if line.startswith(\" \") else \"\\n\") + line.strip() for line in lines]\n",
    "            res = ''.join(out).split('\\n')[1:]\n",
    "            article_str = ' '.join(res)\n",
    "            article_str = article_str.replace(u'\\xa0', u' ')\n",
    "            \n",
    "            result_dict_re[directory[-4:] +'/'+ filename] = extract_all_percent_re(article_str)\n",
    "            count += 1\n",
    "            if count % 10 == 0:\n",
    "                print(str(count) + '/730')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/730\n",
      "20/730\n",
      "30/730\n",
      "40/730\n",
      "50/730\n",
      "60/730\n",
      "70/730\n",
      "80/730\n",
      "90/730\n",
      "100/730\n",
      "110/730\n",
      "120/730\n",
      "130/730\n",
      "140/730\n",
      "150/730\n",
      "160/730\n",
      "170/730\n",
      "180/730\n",
      "190/730\n",
      "200/730\n",
      "210/730\n",
      "220/730\n",
      "230/730\n",
      "240/730\n",
      "250/730\n",
      "260/730\n",
      "270/730\n",
      "280/730\n",
      "290/730\n",
      "300/730\n",
      "310/730\n",
      "320/730\n",
      "330/730\n",
      "340/730\n",
      "350/730\n",
      "360/730\n",
      "370/730\n",
      "380/730\n",
      "390/730\n",
      "400/730\n",
      "410/730\n",
      "420/730\n",
      "430/730\n",
      "440/730\n",
      "450/730\n",
      "460/730\n",
      "470/730\n",
      "480/730\n",
      "490/730\n",
      "500/730\n",
      "510/730\n",
      "520/730\n",
      "530/730\n",
      "540/730\n",
      "550/730\n",
      "560/730\n",
      "570/730\n",
      "580/730\n",
      "590/730\n",
      "600/730\n",
      "610/730\n",
      "620/730\n",
      "630/730\n",
      "640/730\n",
      "650/730\n",
      "660/730\n",
      "670/730\n",
      "680/730\n",
      "690/730\n",
      "700/730\n",
      "710/730\n",
      "720/730\n",
      "730/730\n"
     ]
    }
   ],
   "source": [
    "# result_dict = {}\n",
    "# count = 0\n",
    "# directory_list = [f'./BI-articles/2013',f'./BI-articles/2014']\n",
    "# for directory in directory_list:\n",
    "#     for file in os.listdir(directory):\n",
    "#         filename = os.fsdecode(file)\n",
    "#         if filename.endswith(\".txt\"):\n",
    "                    \n",
    "\n",
    "#             with open(directory +'/'+ filename,'r', errors='replace') as f:\n",
    "#                 lines = f.readlines()\n",
    "#             out = [(\" \" if line.startswith(\" \") else \"\\n\") + line.strip() for line in lines]\n",
    "#             res = ''.join(out).split('\\n')[1:]\n",
    "#             article_str = ' '.join(res)\n",
    "#             article_str = article_str.replace(u'\\xa0', u' ')\n",
    "            \n",
    "#             result_dict[directory[-4:] +'/'+ filename] = extract_all_percent(article_str, percent_word_list)\n",
    "#             count += 1\n",
    "#             if count % 10 == 0:\n",
    "#                 print(str(count) + '/730')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_result_list = []\n",
    "# for key, value in result_dict.items():\n",
    "#     all_result_list += value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_result_list_re = []\n",
    "for key, value in result_dict_re.items():\n",
    "    all_result_list_re += value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_to_percent_string(value):\n",
    "#     return '{}%'.format(value * 100)\n",
    "percent_labels = pd.read_csv('./labels/percentage.csv', header = None, encoding = \"ISO-8859-1\", names = ['percents'], dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_article = ''\n",
    "\n",
    "directory_list = [f'./BI-articles/2013',f'./BI-articles/2014']\n",
    "for directory in directory_list:\n",
    "    for file in os.listdir(directory):\n",
    "        filename = os.fsdecode(file)\n",
    "        if filename.endswith(\".txt\"):\n",
    "                    \n",
    "\n",
    "            with open(directory +'/'+ filename,'r', errors='replace') as f:\n",
    "                lines = f.readlines()\n",
    "            out = [(\" \" if line.startswith(\" \") else \"\\n\") + line.strip() for line in lines]\n",
    "            res = ''.join(out).split('\\n')[1:]\n",
    "            article_str = ' '.join(res)\n",
    "            article_str = article_str.replace(u'\\xa0', u' ')\n",
    "            \n",
    "            all_article += (article_str + ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "half a percent\n",
      "half a percent\n",
      "80 to 90 percent\n",
      "zero%\n",
      "16 1%\n",
      "2 71%\n",
      "2 75%\n",
      "a half of a percentage point\n",
      "a quarter of a percentage point\n",
      "found proportion:  0.9970247933884298\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "found_count = 0\n",
    "for percent_label in percent_labels['percents']:\n",
    "    if ('%' in percent_label or 'percent' in percent_label) and ('\\'' not in percent_label) and ('\\\"' not in percent_label):\n",
    "        if percent_label in all_article:\n",
    "            #valid true label count\n",
    "            count += 1\n",
    "            \n",
    "            if percent_label in ' '.join(all_result_list_re):\n",
    "                found_count += 1\n",
    "            else:\n",
    "                #print not found label\n",
    "                print(percent_label)\n",
    "print('found proportion: ', found_count/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine_result_set = set()\n",
    "# for result in (all_result_list + all_result_list_re):\n",
    "#     combine_result_set.add(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for percent_label in percent_labels['percents']:\n",
    "#     if ('%' in percent_label or 'percent' in percent_label) and ('\\'' not in percent_label) and ('\\\"' not in percent_label):\n",
    "        \n",
    "#         if percent_label not in ' '.join(all_result_list_re + all_result_list):\n",
    "#             if percent_label in all_article:\n",
    "#                 print(percent_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(all_result_list_re).to_excel('all_extract_percent_re.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
